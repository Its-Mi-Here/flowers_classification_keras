{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import shutil\n",
    "from scipy.io import loadmat\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Activation, MaxPooling2D, Flatten, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.layers import Flatten, Dense, BatchNormalization, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unpacking labels from mat file and storing in 'data' array\n",
    "labels1 = loadmat('imagelabels.mat')\n",
    "data = [[row.flat[0] for row in line] for line in labels1['labels']]\n",
    "\n",
    "\n",
    "#Creating array to store names of all images in dataset\n",
    "arr = []\n",
    "for i in range(1,8190):\n",
    "    if(i<=9):\n",
    "        arr.append('image_0000{}.jpg'.format(i))\n",
    "        continue\n",
    "    if(i<=99):\n",
    "        arr.append('image_000{}.jpg'.format(i))\n",
    "        continue\n",
    "    if(i<=999):\n",
    "        arr.append('image_00{}.jpg'.format(i))\n",
    "        continue\n",
    "    if(i<=9999):\n",
    "        arr.append('image_0{}.jpg'.format(i))\n",
    "        continue\n",
    "\n",
    "\n",
    "#Combining labels and names of images in a dataframe\n",
    "train = pd.DataFrame(data = [data[0], arr])\n",
    "train = train.transpose()\n",
    "columns = ['Category', 'Name']\n",
    "train.columns = columns\n",
    "\n",
    "\n",
    "#Spliting dataset in train and test\n",
    "train1, test1 = train_test_split(train, test_size=0.35)\n",
    "TRAIN_INSTANCES = np.shape(train1)[0]\n",
    "TEST_INSTANCES = np.shape(test1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN ONLY ONCE\n",
    "\n",
    "#Creating different directories for train and test and all the subdirectories-class 1 to 102\n",
    "\n",
    "os.mkdir('jpg/train')\n",
    "for x in train1['Name']:\n",
    "    shutil.move(src = 'jpg/{}'.format(x), dst = 'jpg/train')\n",
    "    \n",
    "os.mkdir('jpg/test')\n",
    "for x in test1['Name']:\n",
    "    shutil.move(src = 'jpg/{}'.format(x), dst = 'jpg/test')\n",
    "    \n",
    "\n",
    "#Creating subdirectories from class 1 to 102\n",
    "uni = []\n",
    "uni = train1['Category'].unique()\n",
    "for i in uni:\n",
    "    os.mkdir('jpg/train/{}'.format(i))\n",
    "    os.mkdir('jpg/test/{}'.format(i))\n",
    "    \n",
    "#Shifting the images into their directories\n",
    "for x in range(0, TRAIN_INSTANCES):\n",
    "    shutil.move('jpg/train/{}'.format(train1.iloc[x][1]), 'jpg/train/{}'.format(train1.iloc[x][0]))\n",
    "\n",
    "for x in range(0, TEST_INSTANCES):\n",
    "    shutil.move('jpg/test/{}'.format(test1.iloc[x][1]), 'jpg/test/{}'.format(test1.iloc[x][0]))\n",
    "    \n",
    "    \n",
    "#After running this cell we get a tree structure of the data for the function 'flow_from_directory'\n",
    "#jpg\n",
    "# -train\n",
    "#   -1 to 102 (classes)\n",
    "# -test\n",
    "#   -1 to 102(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5322 images belonging to 102 classes.\n",
      "Found 2867 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "#Image preprocessing and data augmentation is easily done with ImageDataGenerator, which takes in parameters for preprocessing\n",
    "\n",
    "datagen = ImageDataGenerator(horizontal_flip=True, rescale=1./255, zoom_range=0.2)\n",
    "\n",
    "train_it = datagen.flow_from_directory('jpg/train/', class_mode='binary', batch_size=32, target_size=(200, 200))\n",
    "test_it = datagen.flow_from_directory('jpg/test/', class_mode='binary', batch_size=32, target_size=(200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 100, 100, 50)      2450      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 50, 50, 50)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 50, 50, 50)        200       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50, 50, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 60)        27060     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 60)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 12, 60)        240       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 12, 12, 60)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8640)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               2212096   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 102)               26214     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 102)               0         \n",
      "=================================================================\n",
      "Total params: 2,268,260\n",
      "Trainable params: 2,268,040\n",
      "Non-trainable params: 220\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Defining our model with CNN blocks, Pooling layers and lastly the fully connected layers\n",
    "\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "#Input shape is the resized image shape we have defined with parameter 'target_size' in the flow_from_directory function\n",
    "model.add(Conv2D(50, (4,4),input_shape=(200,200,3), padding='same', activation='relu', strides=(2,2)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(60, (3,3), activation='relu', strides=(2,2)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(102))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss is 'sparse_categorical' because one instance of image belongs to exactly one class\n",
    "model.compile(loss='sparse_categorical_crossentropy',  optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving model \n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is to reduce learning rate automatically if overshooting or plateauing of validation loss is observed\n",
    "lrr= ReduceLROnPlateau(monitor='val_loss', factor=.01, patience=3, min_lr=1e-5)\n",
    "\n",
    "#ModelCheckpoint helps us to save the weights after each iteration\n",
    "checkpointer = ModelCheckpoint(filepath = 'weights.hdf5', verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total instance//batchsize\n",
    "STEP_SIZE_TRAIN = 5322//32\n",
    "STEP_SIZE_TEST = 2867//32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "166/166 [==============================] - 215s 1s/step - loss: 4.0723 - accuracy: 0.1342 - val_loss: 7.4319 - val_accuracy: 0.0049\n",
      "\n",
      "Epoch 00001: saving model to weights_4Feb.hdf5\n",
      "Epoch 2/50\n",
      "166/166 [==============================] - 223s 1s/step - loss: 3.0082 - accuracy: 0.2701 - val_loss: 9.0589 - val_accuracy: 0.0473\n",
      "\n",
      "Epoch 00002: saving model to weights_4Feb.hdf5\n",
      "Epoch 3/50\n",
      "166/166 [==============================] - 245s 1s/step - loss: 2.3818 - accuracy: 0.3930 - val_loss: 4.3042 - val_accuracy: 0.1679\n",
      "\n",
      "Epoch 00003: saving model to weights_4Feb.hdf5\n",
      "Epoch 4/50\n",
      "166/166 [==============================] - 237s 1s/step - loss: 2.0145 - accuracy: 0.4629 - val_loss: 2.4747 - val_accuracy: 0.3266\n",
      "\n",
      "Epoch 00004: saving model to weights_4Feb.hdf5\n",
      "Epoch 5/50\n",
      "166/166 [==============================] - 232s 1s/step - loss: 1.7716 - accuracy: 0.5297 - val_loss: 2.1267 - val_accuracy: 0.4028\n",
      "\n",
      "Epoch 00005: saving model to weights_4Feb.hdf5\n",
      "Epoch 6/50\n",
      "166/166 [==============================] - 245s 1s/step - loss: 1.5250 - accuracy: 0.5845 - val_loss: 4.9797 - val_accuracy: 0.2522\n",
      "\n",
      "Epoch 00006: saving model to weights_4Feb.hdf5\n",
      "Epoch 7/50\n",
      "166/166 [==============================] - 316s 2s/step - loss: 1.3027 - accuracy: 0.6363 - val_loss: 4.6833 - val_accuracy: 0.2878\n",
      "\n",
      "Epoch 00007: saving model to weights_4Feb.hdf5\n",
      "Epoch 8/50\n",
      "166/166 [==============================] - 339s 2s/step - loss: 1.1762 - accuracy: 0.6690 - val_loss: 1.7788 - val_accuracy: 0.4367\n",
      "\n",
      "Epoch 00008: saving model to weights_4Feb.hdf5\n",
      "Epoch 9/50\n",
      "166/166 [==============================] - 333s 2s/step - loss: 1.0282 - accuracy: 0.7015 - val_loss: 2.8860 - val_accuracy: 0.4825\n",
      "\n",
      "Epoch 00009: saving model to weights_4Feb.hdf5\n",
      "Epoch 10/50\n",
      "166/166 [==============================] - 318s 2s/step - loss: 0.9200 - accuracy: 0.7355 - val_loss: 2.1802 - val_accuracy: 0.4938\n",
      "\n",
      "Epoch 00010: saving model to weights_4Feb.hdf5\n",
      "Epoch 11/50\n",
      "166/166 [==============================] - 323s 2s/step - loss: 0.8262 - accuracy: 0.7612 - val_loss: 2.2923 - val_accuracy: 0.4787\n",
      "\n",
      "Epoch 00011: saving model to weights_4Feb.hdf5\n",
      "Epoch 12/50\n",
      "166/166 [==============================] - 323s 2s/step - loss: 0.6358 - accuracy: 0.8083 - val_loss: 1.7072 - val_accuracy: 0.5189\n",
      "\n",
      "Epoch 00012: saving model to weights_4Feb.hdf5\n",
      "Epoch 13/50\n",
      "166/166 [==============================] - 300s 2s/step - loss: 0.5468 - accuracy: 0.8412 - val_loss: 1.4197 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00013: saving model to weights_4Feb.hdf5\n",
      "Epoch 14/50\n",
      "166/166 [==============================] - 303s 2s/step - loss: 0.5215 - accuracy: 0.8471 - val_loss: 3.3956 - val_accuracy: 0.5379\n",
      "\n",
      "Epoch 00014: saving model to weights_4Feb.hdf5\n",
      "Epoch 15/50\n",
      "166/166 [==============================] - 300s 2s/step - loss: 0.5036 - accuracy: 0.8518 - val_loss: 1.6994 - val_accuracy: 0.5259\n",
      "\n",
      "Epoch 00015: saving model to weights_4Feb.hdf5\n",
      "Epoch 16/50\n",
      "166/166 [==============================] - 340s 2s/step - loss: 0.4782 - accuracy: 0.8611 - val_loss: 2.1287 - val_accuracy: 0.5563\n",
      "\n",
      "Epoch 00016: saving model to weights_4Feb.hdf5\n",
      "Epoch 17/50\n",
      "166/166 [==============================] - 365s 2s/step - loss: 0.4746 - accuracy: 0.8580 - val_loss: 2.2582 - val_accuracy: 0.5330\n",
      "\n",
      "Epoch 00017: saving model to weights_4Feb.hdf5\n",
      "Epoch 18/50\n",
      "166/166 [==============================] - 280s 2s/step - loss: 0.4515 - accuracy: 0.8677 - val_loss: 1.7686 - val_accuracy: 0.5580\n",
      "\n",
      "Epoch 00018: saving model to weights_4Feb.hdf5\n",
      "Epoch 19/50\n",
      "166/166 [==============================] - 289s 2s/step - loss: 0.4453 - accuracy: 0.8684 - val_loss: 1.6046 - val_accuracy: 0.5527\n",
      "\n",
      "Epoch 00019: saving model to weights_4Feb.hdf5\n",
      "Epoch 20/50\n",
      "166/166 [==============================] - 275s 2s/step - loss: 0.4551 - accuracy: 0.8677 - val_loss: 1.9866 - val_accuracy: 0.5531\n",
      "\n",
      "Epoch 00020: saving model to weights_4Feb.hdf5\n",
      "Epoch 21/50\n",
      "  4/166 [..............................] - ETA: 3:28 - loss: 0.5978 - accuracy: 0.8281"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-f7183616143a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_it\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSTEP_SIZE_TRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_it\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSTEP_SIZE_TEST\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlrr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpointer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m                 \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m                 initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m         \u001b[1;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Accidentally went ahead with 50 epochs to stopped after 20 with a keyboard interrupt\n",
    "train_history = model.fit(train_it, steps_per_epoch = STEP_SIZE_TRAIN, epochs = 50, validation_data = test_it, validation_steps = STEP_SIZE_TEST, callbacks = [lrr, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
